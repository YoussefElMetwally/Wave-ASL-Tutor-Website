{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79033276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "# This script loads the collected keypoint data, preprocesses it,\n",
    "# builds an LSTM model, and trains it to recognize ASL signs.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# These parameters must match the data collection script and your data structure.\n",
    "DATA_PATH = os.path.join('data')\n",
    "MODEL_SAVE_PATH = os.path.join('models')\n",
    "LOG_DIR = os.path.join('Logs')\n",
    "\n",
    "# Base actions (e.g., '10', '11', ... '20')\n",
    "ACTIONS_BASE = [str(i) for i in range(10, 21)]\n",
    "\n",
    "# Parameters from the capture script\n",
    "SEQUENCE_LENGTH = 30  # Frames per sequence\n",
    "\n",
    "# Keypoint vector length (NO Z coordinate)\n",
    "# Pose: 33 landmarks * (x, y, visibility) = 99\n",
    "# Hands: 21 landmarks * (x, y) = 42 per hand\n",
    "# Total = 99 + 42 + 42 = 183\n",
    "KEYPOINT_VECTOR_LENGTH = 183\n",
    "\n",
    "# --- 2. Create Paths ---\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# --- 3. Landmark Constants & Helper Functions (Corrected & Robust) ---\n",
    "NUM_POSE_LANDMARKS = 33\n",
    "NUM_HAND_LANDMARKS = 21\n",
    "\n",
    "# Indices for mirroring (swapping left and right body parts)\n",
    "POSE_LANDMARK_PAIRS = {11: 12, 13: 14, 15: 16, 23: 24, 25: 26, 27: 28, 29: 30, 31: 32}\n",
    "POSE_LANDMARK_PAIRS.update({v: k for k, v in POSE_LANDMARK_PAIRS.items()})\n",
    "\n",
    "def mirror_keypoints_frame(keypoints_frame):\n",
    "    \"\"\" Correctly mirrors a 183-length keypoint vector to canonicalize left-hand signs. \"\"\"\n",
    "    mirrored_frame = np.copy(keypoints_frame)\n",
    "\n",
    "    # --- 1. Mirror X-coordinates (around the center 0.5) ---\n",
    "    # Pose: 3 coords (x, y, vis). X is at index 0, 3, 6, ...\n",
    "    for i in range(NUM_POSE_LANDMARKS):\n",
    "        mirrored_frame[i * 3] = 1.0 - mirrored_frame[i * 3]\n",
    "    # Hands: 2 coords (x, y). X is at index 0, 2, 4, ...\n",
    "    lh_start_idx = NUM_POSE_LANDMARKS * 3\n",
    "    rh_start_idx = lh_start_idx + NUM_HAND_LANDMARKS * 2\n",
    "    for i in range(NUM_HAND_LANDMARKS):\n",
    "        mirrored_frame[lh_start_idx + i * 2] = 1.0 - mirrored_frame[lh_start_idx + i * 2]\n",
    "        mirrored_frame[rh_start_idx + i * 2] = 1.0 - mirrored_frame[rh_start_idx + i * 2]\n",
    "\n",
    "    # --- 2. Swap Left and Right Hand Data Blocks ---\n",
    "    original_mirrored_lh_data = mirrored_frame[lh_start_idx:rh_start_idx].copy()\n",
    "    original_mirrored_rh_data = mirrored_frame[rh_start_idx:].copy()\n",
    "    mirrored_frame[lh_start_idx:rh_start_idx] = original_mirrored_rh_data\n",
    "    mirrored_frame[rh_start_idx:] = original_mirrored_lh_data\n",
    "\n",
    "    # --- 3. Swap Paired Pose Landmarks ---\n",
    "    temp_pose_data = mirrored_frame[:NUM_POSE_LANDMARKS * 3].copy().reshape(NUM_POSE_LANDMARKS, 3)\n",
    "    final_pose_data = temp_pose_data.copy()\n",
    "    for l_idx, r_idx in POSE_LANDMARK_PAIRS.items():\n",
    "        final_pose_data[l_idx] = temp_pose_data[r_idx]\n",
    "    mirrored_frame[:NUM_POSE_LANDMARKS * 3] = final_pose_data.flatten()\n",
    "    return mirrored_frame\n",
    "\n",
    "def normalize_sequence(sequence_data):\n",
    "    \"\"\"\n",
    "    Robustly normalizes a sequence of 183-length keypoint vectors.\n",
    "    - Translation: Relative to the midpoint of the hips (2D).\n",
    "    - Scale: Relative to the distance between the shoulders (2D).\n",
    "    \"\"\"\n",
    "    normalized_sequence = []\n",
    "    for frame_kps in sequence_data:\n",
    "        if np.all(frame_kps == 0):\n",
    "            normalized_sequence.append(frame_kps)\n",
    "            continue\n",
    "\n",
    "        # Reshape for easier calculations (183 vector -> pose, lh, rh)\n",
    "        pose_kps = frame_kps[:99].reshape(33, 3)\n",
    "        lh_kps = frame_kps[99:141].reshape(21, 2)\n",
    "        rh_kps = frame_kps[141:].reshape(21, 2)\n",
    "\n",
    "        # --- 1. Translation Normalization (center on hip midpoint) ---\n",
    "        hip_l, hip_r = pose_kps[23], pose_kps[24]\n",
    "        # Check visibility flag (3rd value, index 2) to find a stable origin\n",
    "        if hip_l[2] > 0.5 and hip_r[2] > 0.5:\n",
    "            origin = (hip_l[:2] + hip_r[:2]) / 2.0\n",
    "        elif hip_l[2] > 0.5:\n",
    "            origin = hip_l[:2]\n",
    "        elif hip_r[2] > 0.5:\n",
    "            origin = hip_r[:2]\n",
    "        else:  # Fallback to nose if hips are not visible\n",
    "            origin = pose_kps[0][:2]\n",
    "\n",
    "        # Subtract the origin from all x,y coordinates\n",
    "        pose_kps[:, :2] -= origin\n",
    "        lh_kps -= origin\n",
    "        rh_kps -= origin\n",
    "\n",
    "        # --- 2. Scale Normalization (relative to shoulder distance) ---\n",
    "        shoulder_l, shoulder_r = pose_kps[11], pose_kps[12]\n",
    "        if shoulder_l[2] > 0.5 and shoulder_r[2] > 0.5:\n",
    "            # Use L2 norm for 2D distance\n",
    "            scale = np.linalg.norm(shoulder_l[:2] - shoulder_r[:2])\n",
    "            if scale < 1e-6:  # Avoid division by zero\n",
    "                scale = 1.0\n",
    "        else:  # If shoulders not visible, don't scale\n",
    "            scale = 1.0\n",
    "\n",
    "        pose_kps[:, :2] /= scale\n",
    "        lh_kps /= scale\n",
    "        rh_kps /= scale\n",
    "\n",
    "        # Flatten back into a single 183-length vector\n",
    "        processed_frame = np.concatenate([pose_kps.flatten(), lh_kps.flatten(), rh_kps.flatten()])\n",
    "        normalized_sequence.append(processed_frame)\n",
    "\n",
    "    return np.array(normalized_sequence)\n",
    "\n",
    "def main():\n",
    "    # --- 4. Data Loading and Preprocessing ---\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    sequences, labels = [], []\n",
    "    label_map = {label: num for num, label in enumerate(ACTIONS_BASE)}\n",
    "\n",
    "    with open(os.path.join(MODEL_SAVE_PATH, 'label_map.json'), 'w') as f:\n",
    "        json.dump(label_map, f)\n",
    "    print(f\"Label map created: {label_map}\")\n",
    "\n",
    "    action_variants = [d for d in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, d))]\n",
    "\n",
    "    for action_variant in sorted(action_variants):  # Sort for consistent order\n",
    "        action_base = action_variant.split('_')[0]\n",
    "        if action_base not in ACTIONS_BASE:\n",
    "            print(f\"Skipping unexpected folder: {action_variant}\")\n",
    "            continue\n",
    "\n",
    "        is_left_handed_sample = \"_L\" in action_variant\n",
    "        action_variant_path = os.path.join(DATA_PATH, action_variant)\n",
    "\n",
    "        for seq_name in sorted(os.listdir(action_variant_path)):\n",
    "            sequence_path = os.path.join(action_variant_path, seq_name)\n",
    "\n",
    "            num_frames = len([f for f in os.listdir(sequence_path) if f.endswith('.npy')])\n",
    "            if num_frames != SEQUENCE_LENGTH:\n",
    "                print(f\"Warning: Skipping {action_variant}/{seq_name}. Found {num_frames} frames, expected {SEQUENCE_LENGTH}.\")\n",
    "                continue\n",
    "\n",
    "            window = []\n",
    "            for frame_num in range(SEQUENCE_LENGTH):\n",
    "                res = np.load(os.path.join(sequence_path, f\"{frame_num}.npy\"))\n",
    "                if is_left_handed_sample:\n",
    "                    res = mirror_keypoints_frame(res)\n",
    "                window.append(res)\n",
    "            \n",
    "            # Normalize the entire sequence\n",
    "            normalized_window = normalize_sequence(np.array(window))\n",
    "            sequences.append(normalized_window)\n",
    "            labels.append(label_map[action_base])\n",
    "\n",
    "    if not sequences:\n",
    "        raise RuntimeError(\"No data loaded. Check DATA_PATH and ensure subdirectories contain complete sequences.\")\n",
    "\n",
    "    X = np.array(sequences)\n",
    "    y = to_categorical(labels, num_classes=len(ACTIONS_BASE)).astype(int)\n",
    "    print(f\"\\nData Loaded. X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    # --- 5. Splitting Data ---\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, random_state=42, stratify=y_train_val)\n",
    "    print(f\"Train/Val/Test split: {len(X_train)}/{len(X_val)}/{len(X_test)}\")\n",
    "\n",
    "    # --- 6. Model Architecture (The successful architecture from your notebook) ---\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, activation='tanh', recurrent_activation='sigmoid',\n",
    "             input_shape=(SEQUENCE_LENGTH, KEYPOINT_VECTOR_LENGTH), kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        LSTM(256, return_sequences=True, activation='tanh', recurrent_activation='sigmoid', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        LSTM(128, return_sequences=False, activation='tanh', recurrent_activation='sigmoid', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "\n",
    "        Dense(len(ACTIONS_BASE), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # --- 7. Compile and Train Model ---\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    log_dir_ts = os.path.join(LOG_DIR, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    checkpoint_filepath = os.path.join(MODEL_SAVE_PATH, 'best_action_model.h5')\n",
    "\n",
    "    callbacks = [\n",
    "        TensorBoard(log_dir=log_dir_ts),\n",
    "        ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, monitor='val_categorical_accuracy', mode='max', save_best_only=True, verbose=1),\n",
    "        EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='min', restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, mode='min', min_lr=1e-6)\n",
    "    ]\n",
    "\n",
    "    EPOCHS = 300\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    # --- 8. Evaluate Best Model on Test Set ---\n",
    "    print(\"\\nEvaluating best model on Test Set...\")\n",
    "    best_model = load_model(checkpoint_filepath)\n",
    "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # --- 9. Plotting Training History (Optional) ---\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['categorical_accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(MODEL_SAVE_PATH, 'training_history.png'))\n",
    "        plt.show()\n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not found. Skipping plotting of training history.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
